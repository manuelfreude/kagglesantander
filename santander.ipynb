{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "805091f330f2ed366d6d02ba2540dcb00efdc7a1"
   },
   "source": [
    "# Santander Customer Transaction Prediction\n",
    "https://www.kaggle.com/c/santander-customer-transaction-prediction/data\n",
    "\n",
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File descriptions\n",
    "\n",
    "    train.csv - the training set.\n",
    "    test.csv - the test set. The test set contains some rows which are not included in scoring.\n",
    "    sample_submission.csv - a sample submission file in the correct format.\n",
    "    \n",
    "    \n",
    "### Data Fields\n",
    "\n",
    "You are provided with an anonymized dataset containing numeric feature variables, the binary target column, and a string ID_code column.\n",
    "\n",
    "The task is to predict the value of target column in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data\n",
    "\n",
    "### Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9dc5b2517bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Library import \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the csv files\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_IDtarget = pd.DataFrame(columns=['ID_code', 'target'])\n",
    "test_ID = pd.DataFrame(columns=['ID_code'])\n",
    "\n",
    "train_IDtarget['ID_code'] = train['ID_code']\n",
    "train_IDtarget['target'] = train['target']\n",
    "test_ID['ID_code'] = test['ID_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['ID_code', 'target'], axis=1)\n",
    "train = normalize(train)\n",
    "train = pd.DataFrame(data=train)\n",
    "train = pd.concat([train_IDtarget, train], axis=1)\n",
    "\n",
    "test = test.drop(['ID_code'], axis=1)\n",
    "test = normalize(test)\n",
    "test = pd.DataFrame(data=test)\n",
    "test = pd.concat([test_ID, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(7, 7), sharex=True)\n",
    "sns.distplot(train['1'], color='skyblue', ax=axes[0, 0])\n",
    "sns.distplot(train['2'], color='olive', ax=axes[0, 1])\n",
    "sns.distplot(train['3'], color='gold', ax=axes[1, 0])\n",
    "sns.distplot(train['4'], color='teal', ax=axes[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train)\n",
    "sns.plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(train, alpha = 0.3, figsize = (14,8), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b0b651002ad69c424996b1cb63c978099499cd9"
   },
   "source": [
    "## Data cleanup and feature engineering\n",
    "### Data fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try:\n",
    "\n",
    "*Training data*\n",
    "- Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataset and normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset\n",
    "\n",
    "The feature engineering conducted for the training dataset will be done for test data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling test datafields, sentiment, CNN adoption prediction and dataset merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n",
    "\n",
    "\n",
    "**Score function used for algorithm development**\n",
    "\n",
    "For internal training, the scikit classification evaluation methods accuracy score, precision, recall and f1 score will be used in addition to the overall scoring function (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and creating scores table\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "scores = pd.DataFrame(columns=['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1', 'ROC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train validation split\n",
    "\n",
    "We can create a train test split on the training data before we can expose our model to the test dataset at first place. The train dataset includes 200,000 rows, the given test dataset 200,000 rows.\n",
    "\n",
    "The train set will be split into 160,000 training rows and 40,000 validation rows. The models will be trained on this data before predicting data along the test set. For simplicity, the artificial test set will be referred to as \"validation set\". Implementation will be along one comprehensive dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data = train_test_split(full_train, train_size=0.8, shuffle=True, random_state=25)\n",
    "\n",
    "print('Observations: %d' % (len(full_train)))\n",
    "print('Training Observations: %d' % (len(train_data)))\n",
    "print('Validation Observations: %d' % (len(valid_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6dbf640f2e00686342b8744755cef364ba334522"
   },
   "source": [
    "## Develop the classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "285935371fd735615943b51872ba00e9cfe765e7"
   },
   "source": [
    "Following classifier models will be tried for this project: \n",
    "- https://scikit-learn.org/stable/modules/sgd.html#classification\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "- https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a29f446d9743f28d23cb7c510e86f21da9706ec"
   },
   "source": [
    "### Selecting model input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incl. check to keep only the full minus one dummies per original variable\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer()\n",
    "\n",
    "train_variables = train_data.drop(['ID_code', 'target'], axis=1)\n",
    "\n",
    "train_variables = imputer.fit_transform(train_variables)\n",
    "\n",
    "train_targets = train_data['target']\n",
    "\n",
    "valid_variables = valid_data.drop(['ID_code', 'target'], axis=1)\n",
    "\n",
    "valid_variables = imputer.fit_transform(valid_variables)\n",
    "\n",
    "valid_targets = valid_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab16aa03b1dc2744c46f52d9d017c82f2458a857"
   },
   "source": [
    "### Stochastic Gradient Descent (SGD) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/sgd.html#classification\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGD_model = SGDClassifier(alpha=0.0001, epsilon=0.1, eta0=0.0, fit_intercept=True, \n",
    "                          learning_rate='optimal', loss=\"hinge\", penalty=\"l2\", max_iter=5, random_state=25)\n",
    "\n",
    "SGD_model.fit(train_variables, train_targets)\n",
    "\n",
    "SGD_preds = SGD_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'SGD'\n",
    "accuracy = accuracy_score(valid_targets, SGD_preds)\n",
    "precision = precision_score(valid_targets, SGD_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, SGD_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, SGD_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, SGD_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69a0ae72f3bca6ae229261f75571d5ddc996bf59"
   },
   "source": [
    "### k neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b489956257b2096807760a3bc0b2b0f3475c3a6b"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kneigh_model = KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "kneigh_model.fit(train_variables, train_targets)\n",
    "\n",
    "kneigh_preds = kneigh_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'kNeigh'\n",
    "accuracy = accuracy_score(valid_targets, kneigh_preds)\n",
    "precision = precision_score(valid_targets, kneigh_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, kneigh_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, kneigh_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, kneigh_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP_model = MLPClassifier(hidden_layer_sizes=(100, ), \n",
    "                          activation='relu', \n",
    "                          solver='adam', \n",
    "                          alpha=0.0001, \n",
    "                          batch_size='auto', \n",
    "                          learning_rate='constant', \n",
    "                          learning_rate_init=0.001,\n",
    "                          random_state=25)\n",
    "\n",
    "MLP_model.fit(train_variables, train_targets)\n",
    "\n",
    "MLP_preds = MLP_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'MLP'\n",
    "accuracy = accuracy_score(valid_targets, MLP_preds)\n",
    "precision = precision_score(valid_targets, MLP_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, MLP_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, MLP_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, MLP_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC_model = SVC(random_state=25)\n",
    "\n",
    "SVC_model.fit(train_variables, train_targets)\n",
    "\n",
    "SVC_preds = SVC_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'SVC'\n",
    "accuracy = accuracy_score(valid_targets, SVC_preds)\n",
    "precision = precision_score(valid_targets, SVC_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, SVC_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, SVC_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, SVC_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear support vector classifier (Linear SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "LinSVC_model = LinearSVC(random_state=25)\n",
    "\n",
    "LinSVC_model.fit(train_variables, train_targets)\n",
    "\n",
    "LinSVC_preds = LinSVC_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'Linear SVC'\n",
    "accuracy = accuracy_score(valid_targets, LinSVC_preds)\n",
    "precision = precision_score(valid_targets, LinSVC_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, LinSVC_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, LinSVC_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, LinSVC_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DecTree_model = DecisionTreeClassifier(random_state=25)\n",
    "\n",
    "DecTree_model.fit(train_variables, train_targets)\n",
    "\n",
    "DecTree_preds = DecTree_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'Decision Tree'\n",
    "accuracy = accuracy_score(valid_targets, DecTree_preds)\n",
    "precision = precision_score(valid_targets, DecTree_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, DecTree_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, DecTree_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, DecTree_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GradBoost_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=25)\n",
    "\n",
    "GradBoost_model.fit(train_variables, train_targets)\n",
    "\n",
    "GradBoost_preds = GradBoost_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'Gradient Boost'\n",
    "accuracy = accuracy_score(valid_targets, GradBoost_preds)\n",
    "precision = precision_score(valid_targets, GradBoost_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, GradBoost_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, GradBoost_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, GradBoost_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RndmForest_model = RandomForestClassifier(random_state=25)\n",
    "\n",
    "RndmForest_model.fit(train_variables, train_targets)\n",
    "\n",
    "RndmForest_preds = RndmForest_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'Random Forest'\n",
    "accuracy = accuracy_score(valid_targets, RndmForest_preds)\n",
    "precision = precision_score(valid_targets, RndmForest_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, RndmForest_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, RndmForest_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, RndmForest_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "base_estimator = GradientBoostingClassifier(learning_rate=0.1, random_state=25)\n",
    "\n",
    "Bagging_model = BaggingClassifier(base_estimator=base_estimator, random_state=25)\n",
    "\n",
    "Bagging_model.fit(train_variables, train_targets)\n",
    "\n",
    "Bagging_preds = Bagging_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'Bagging'\n",
    "accuracy = accuracy_score(valid_targets, Bagging_preds)\n",
    "precision = precision_score(valid_targets, Bagging_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, Bagging_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, Bagging_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, Bagging_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "base_estimator = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=25)\n",
    "\n",
    "AdaBoost_model = AdaBoostClassifier(base_estimator=base_estimator, \n",
    "                                    algorithm='SAMME', \n",
    "                                    learning_rate=0.001,\n",
    "                                    random_state=25)\n",
    "\n",
    "AdaBoost_model.fit(train_variables, train_targets)\n",
    "\n",
    "AdaBoost_preds = AdaBoost_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'AdaBoost'\n",
    "accuracy = accuracy_score(valid_targets, AdaBoost_preds)\n",
    "precision = precision_score(valid_targets, AdaBoost_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, AdaBoost_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, AdaBoost_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, AdaBoost_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGBoost_model = XGBClassifier(learning_rate=0.001, random_state=25)\n",
    "\n",
    "XGBoost_model.fit(train_variables, train_targets)\n",
    "\n",
    "XGBoost_preds = XGBoost_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'XGBoost'\n",
    "accuracy = accuracy_score(valid_targets, XGBoost_preds)\n",
    "precision = precision_score(valid_targets, XGBoost_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, XGBoost_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, XGBoost_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, XGBoost_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at performance scores\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy comparison\n",
    "\n",
    "plt.bar(scores['Classifier'], scores['Accuracy'], color='C1')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.xlabel('Classifiers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting precision comparison\n",
    "\n",
    "plt.bar(scores['Classifier'], scores['Precision'], color='C5')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Precision Score')\n",
    "plt.xlabel('Classifiers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting recall comparison\n",
    "\n",
    "plt.bar(scores['Classifier'], scores['Recall'], color='C8')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Recall Score')\n",
    "plt.xlabel('Classifiers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting F1 comparison\n",
    "\n",
    "plt.bar(scores['Classifier'], scores['F1'], color='C9')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Classifiers');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Cohen's kappa comparison\n",
    "\n",
    "plt.bar(scores['Classifier'], scores['ROC'], color='C2')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('ROC curve area')\n",
    "plt.xlabel('Classifiers');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top performer fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/\n",
    "# Params useful for grid search in gradient boosting: n_estimators and learning rate\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "GradBoost_simple = GradientBoostingClassifier()\n",
    "\n",
    "roc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "n_estimators = [25, 50, 100, 500]\n",
    "\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "\n",
    "grid_search = GridSearchCV(GradBoost_simple, param_grid, scoring=roc_scorer, n_jobs=-1, cv=5, return_train_score=True)\n",
    "grid_result = grid_search.fit(train_variables, train_targets)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Plot results\n",
    "results = np.array(means).reshape(len(learning_rate), len(n_estimators))\n",
    "for i, value in enumerate(learning_rate):\n",
    "    plt.plot(n_estimators, results[i], label='learning_rate: ' + str(value))\n",
    "plt.legend()\n",
    "plt.title(\"Gradient boosting learning rate / n_estimators / ROC curve area\")\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel(\"ROC curve area\")\n",
    "plt.savefig('Santander_ALGORITHM_gridsearch.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the winners are.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GradBoost_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=25)\n",
    "\n",
    "GradBoost_model.fit(train_variables, train_targets)\n",
    "\n",
    "GradBoost_preds = GradBoost_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'Gradient Boost (Tuned)'\n",
    "accuracy = accuracy_score(valid_targets, GradBoost_preds)\n",
    "precision = precision_score(valid_targets, GradBoost_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, GradBoost_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, GradBoost_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, GradBoost_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "base_estimator = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=25)\n",
    "\n",
    "Bagging_model = BaggingClassifier(n_estimators=250, base_estimator=base_estimator, random_state=25)\n",
    "\n",
    "Bagging_model.fit(train_variables, train_targets)\n",
    "\n",
    "Bagging_preds = Bagging_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'Bagging (Tuned)'\n",
    "accuracy = accuracy_score(valid_targets, Bagging_preds)\n",
    "precision = precision_score(valid_targets, Bagging_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, Bagging_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, Bagging_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, Bagging_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "base_estimator = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=25)\n",
    "\n",
    "AdaBoost_model = AdaBoostClassifier(base_estimator=base_estimator,\n",
    "                                    n_estimators=250,\n",
    "                                    algorithm='SAMME', \n",
    "                                    learning_rate=0.1,\n",
    "                                    random_state=25)\n",
    "\n",
    "AdaBoost_model.fit(train_variables, train_targets)\n",
    "\n",
    "AdaBoost_preds = AdaBoost_model.predict(valid_variables)\n",
    "\n",
    "classifier = 'AdaBoost (Tuned)'\n",
    "accuracy = accuracy_score(valid_targets, AdaBoost_preds)\n",
    "precision = precision_score(valid_targets, AdaBoost_preds, average='weighted')\n",
    "recall = recall_score(valid_targets, AdaBoost_preds, average='weighted')\n",
    "f1 = f1_score(valid_targets, AdaBoost_preds, average='weighted')\n",
    "ROC = roc_auc_score(valid_targets, AdaBoost_preds)\n",
    "\n",
    "scores = scores.append(pd.Series([classifier, accuracy, precision, recall, f1, ROC], index=scores.columns), ignore_index=True)\n",
    "\n",
    "# Accuracy\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "\n",
    "# Precision\n",
    "print('Precision: %.2f' % precision)\n",
    "\n",
    "# Recall\n",
    "print('Recall: %.2f' % recall)\n",
    "\n",
    "# F1 score\n",
    "print('F1 score: %.2f' % f1)\n",
    "\n",
    "# ROC\n",
    "print('ROC curve area: %.2f' % ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing predictions to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/gaborvecsei/adoption-speed-from-images\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "submission['ID_code'] = full_test['ID_code']\n",
    "\n",
    "submission['target'] = AdaBoost_preds\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('train_facets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
